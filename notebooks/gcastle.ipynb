{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lingam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import sys\n",
    "from lingam.utils import make_dot\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# np.set_printoptions(precision=3, suppress=True, threshold=sys.maxsize)\n",
    "np.random.seed(100)\n",
    "\n",
    "# loading the dataset\n",
    "high_scrap = pd.read_csv(\"dataset/high_scrap.csv\")\n",
    "low_scrap = pd.read_csv(\"dataset/low_scrap.csv\")\n",
    "\n",
    "X = pd.concat([high_scrap, low_scrap])\n",
    "# normalizing\n",
    "X = (X - X.min()) / (X.max() - X.min())\n",
    "\n",
    "# including previous knowledge as a matrix\n",
    "# prior knowledge matrix that have as many rows and columns as the number of columns in the dataset with values -1\n",
    "n = X.shape[1]\n",
    "prior_knowledge = np.full((n, n), -1)\n",
    "# create an array length of number of columns and have as values the number of the station\n",
    "station = np.zeros(n)\n",
    "for i in range(n):\n",
    "    station[i] = X.columns[i][7]\n",
    "\n",
    "# fill the matrix with value 0 when the station is the same\n",
    "for i in range(len(station)):\n",
    "    for j in range(len(station)):\n",
    "        if station[i] < station[j]:\n",
    "            prior_knowledge[i][j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 14:29:35,182 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/dag_gnn/torch/dag_gnn.py[line:165] - INFO: GPU is available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 14:36:08,988 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/dag_gnn/torch/dag_gnn.py[line:253] - INFO: Iter: 0, epoch: 299, h_new: 1.0\n",
      "2024-10-26 14:41:09,366 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/dag_gnn/torch/dag_gnn.py[line:253] - INFO: Iter: 1, epoch: 299, h_new: 0.00022715344547918903\n",
      "2024-10-26 14:51:28,804 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/dag_gnn/torch/dag_gnn.py[line:253] - INFO: Iter: 2, epoch: 299, h_new: 2.5134366893553306e-05\n",
      "2024-10-26 15:01:36,752 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/dag_gnn/torch/dag_gnn.py[line:253] - INFO: Iter: 3, epoch: 299, h_new: 2.6500003258433935e-05\n",
      "2024-10-26 15:06:24,932 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/dag_gnn/torch/dag_gnn.py[line:253] - INFO: Iter: 4, epoch: 299, h_new: 2.6500003258433935e-05\n",
      "2024-10-26 15:11:45,194 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/dag_gnn/torch/dag_gnn.py[line:253] - INFO: Iter: 5, epoch: 299, h_new: 5.222621524580973e-06\n",
      "2024-10-26 15:21:58,476 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/dag_gnn/torch/dag_gnn.py[line:253] - INFO: Iter: 6, epoch: 299, h_new: 4.880158499531717e-06\n",
      "2024-10-26 15:37:22,211 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/dag_gnn/torch/dag_gnn.py[line:253] - INFO: Iter: 7, epoch: 299, h_new: 8.291101352142505e-07\n",
      "2024-10-26 15:53:38,096 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/dag_gnn/torch/dag_gnn.py[line:253] - INFO: Iter: 8, epoch: 299, h_new: 1.3652450547851913e-07\n",
      "2024-10-26 16:07:24,254 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/dag_gnn/torch/dag_gnn.py[line:253] - INFO: Iter: 9, epoch: 299, h_new: 1.6582333728365484e-08\n",
      "2024-10-26 16:22:00,853 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/dag_gnn/torch/dag_gnn.py[line:253] - INFO: Iter: 10, epoch: 299, h_new: 7.222496378744836e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from castle.algorithms import DAG_GNN\n",
    "\n",
    "\n",
    "# structure learning\n",
    "dag_gnn = DAG_GNN(device_type=\"gpu\")\n",
    "dag_gnn.learn(X, k_max_iter=10, h_tolerance=1e-6)\n",
    "dag_gnn.causal_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dag_gnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdag_gnn\u001b[49m\u001b[38;5;241m.\u001b[39mcausal_matrix\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dag_gnn' is not defined"
     ]
    }
   ],
   "source": [
    "dag_gnn.causal_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 16:29:26,781 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/corl/torch/corl.py[line:173] - INFO: GPU is available.\n",
      "2024-10-26 16:29:26,790 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/corl/torch/corl.py[line:233] - INFO: Python version is 3.10.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 16:29:29,713 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/corl/torch/corl.py[line:277] - INFO: Shape of input batch: 98, 98, 100\n",
      "2024-10-26 16:29:29,716 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/corl/torch/corl.py[line:279] - INFO: Shape of input batch: 98, 98, 256\n",
      "2024-10-26 16:29:29,718 - /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/castle/algorithms/gradient/corl/torch/corl.py[line:281] - INFO: Starting training.\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from castle.algorithms import CORL\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "corl = CORL(device_type=\"gpu\", batch_size=98)\n",
    "corl.learn(X)\n",
    "corl.causal_matrix"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
